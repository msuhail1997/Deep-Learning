{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "522_HW2_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cp3sw-xIp6q6"
      },
      "source": [
        "# Homework 2: Deep Learning Diagnostics\n",
        "\n",
        "**Overview**: HW2 will give you a chance to learn how to diagnose problems with neural networks. This skill will prove to be extremely useful when you need to identify a neural network with undesired accuracy or add improvements to an existing model.\n",
        "\n",
        "**Background**: You will be given 10 different neural networks, along with other necessities for training, in a pickled format. All networks will be trained on the Fashion-MNIST dataset, and your job is to identify what exactly is wrong with each training experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "177CxSNaDn30",
        "colab_type": "text"
      },
      "source": [
        "# Q0. Setting up (0 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI8PeRUpIOI8",
        "colab_type": "text"
      },
      "source": [
        "## Installing dependencies\n",
        "\n",
        "Run the code snippet below to import any required dependencies and set up the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-2Bc_BFRp6TO",
        "outputId": "6f8a7451-5f94-4539-dfa3-61659d72248b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import dill\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AJdNInujBP8",
        "colab_type": "code",
        "outputId": "5b6f3f53-c3fd-4974-8289-e009b4126165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho5oFjMUuUfA",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard Setup\n",
        "\n",
        "Run the following code snippets to set up tensorboard. Note that this will save the tensorboard logs in a \"logs\" folder in the ```/content/drive/My Drive/logs``` folder (the root folder of your Drive). If you would like to change where the tensorboard logs are saved, change the ```ROOT_LOG_DIR``` path. Whenever training a different model, we recommend changing the sub-directory in which it's stored -- you can change this by changing the ```TENSORBOARD_DIR``` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QJyvs2JuZQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cyohx5puaOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "ROOT_LOG_DIR = \"/content/drive/My Drive/logs\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kUfNtdDBY73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import dill\n",
        "\n",
        "repo_path = \"/content/Homework2_Resources/\"\n",
        "\n",
        "if not os.path.isdir(repo_path):\n",
        "  !git clone https://github.com/CIS522/Homework2_Resources.git\n",
        "\n",
        "fashion_mnist_test_set_path = \"/content/Homework2_Resources/fashion_test_inputs.dill\"\n",
        "fashion_mnist_data = None\n",
        "with open(fashion_mnist_test_set_path, 'rb') as mnist_f:\n",
        "  fashion_mnist_data = dill.load(mnist_f)\n",
        "\n",
        "CIFAR_test_set_path = \"/content/Homework2_Resources/cifar_10_test_inputs.dill\"\n",
        "CIFAR_data = None\n",
        "with open(CIFAR_test_set_path, 'rb') as cifar_f:\n",
        "  CIFAR_data = dill.load(cifar_f)\n",
        "\n",
        "# If you perform any pre-processing to test_df, please include that pre-processing in this function!\n",
        "def generate_fashion_mnist_output(generate_predictions_func):\n",
        "  return generate_predictions_func(fashion_mnist_data)\n",
        "\n",
        "# If you perform any pre-processing to test_df, please include that pre-processing in this function!\n",
        "def generate_cifar_output(generate_predictions_func):\n",
        "  return generate_predictions_func(CIFAR_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K93hovAUBZbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_case_1e = None\n",
        "test_case_3b = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9EhPbaalVz-",
        "colab_type": "text"
      },
      "source": [
        "# Q1. Introduction to Neural Network Diagnoses, Part 1 (10 pts)\n",
        "\n",
        "**Understanding the Dataset**\n",
        "\n",
        "The first step to machine learning is to understand the dataset that you're given. Therefore, familiarize yourself with the Fashion-MNIST dataset. We recommend reading the paper published about the dataset, which is detailed [here](https://arxiv.org/pdf/1708.07747.pdf).\n",
        "\n",
        "**Q1.a (1 pt):** In the writeup, explain at a high level what the dataset is (i.e. what are the specifications of the input data and associated labels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QumW_aizl9P9",
        "colab_type": "text"
      },
      "source": [
        "##Creating a Benchmark (10 pts)##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az6n2PVDmFSC",
        "colab_type": "text"
      },
      "source": [
        "Below, we will setup a working model for the Fashion-MNIST dataset. This will serve as a benchmark for your analysis in Q2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd3gwyRdlfRE",
        "colab_type": "text"
      },
      "source": [
        "**PyTorch Dataloaders**\n",
        "\n",
        "The first is to create a dataloader:\n",
        "\n",
        "**Q1.b (1 pt):** Create a training, testing, and validation dataloader for the Fashion-MNIST dataset using the data that we provide you. The split should be 70/10/20 respectively. Using any of the three dataloaders, visualize an image from the dataloader and put that image in your writeup.\n",
        "\n",
        "**Note:** Fashion-MNIST is a highly used dataset, but we **do not** want you to use the built in PyTorch Dataset / Dataloader for Fashion-MNIST or any form of this dataset that you find online. We've provided the data for you to use, and so you should be making a custom Dataset / Dataloader, **only** using the data we've given you.\n",
        "\n",
        "**Data:** We've given you the data in the form of two pickled files:\n",
        "*   fashion_input_data.dill\n",
        "*   fashion_labels.dill\n",
        "\n",
        "The first pickled file contains the input data that you should be training with as a pickled 3-dimensional numpy array. The images are 28x28, so each individual image is stored along the first axis (i.e. if you index into [7, 3, 5] you're indexing into the pixel at row 3, column 5 of image).\n",
        "\n",
        "The second pickled file is a numpy array that contains the labels for the input data stored as numbers from 0-9.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLQSK-JBnJ1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/data/fashion_mnist_data/fashion_input_data.dill\",'rb') as fid:\n",
        "  fashion_data  = dill.load(fid)\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/data/fashion_mnist_data/fashion_labels.dill\",'rb') as fl:\n",
        "  fashion_label = dill.load(fl)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO7vGcP94efC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionDataset(Dataset):\n",
        "    def __init__(self,X,y):\n",
        "      self.X=fashion_data\n",
        "      self.y=fashion_label\n",
        "      \n",
        "\n",
        "    def __len__(self):\n",
        "     return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      image=self.X[idx]\n",
        "      label=self.y[idx]\n",
        "     \n",
        "      return image,label\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKdPjyMuuamq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(fashion_data,fashion_label, test_size=0.1, random_state=1)  # splitting total as test-10 and train-90\n",
        "X_train,X_val,Y_train, Y_val = train_test_split(X_train,Y_train,test_size=0.2222, random_state=1) # splitting train-90 as train-70 and val-20 (0.222*90/100 =20)\n",
        "\n",
        "train=FashionDataset(X_train,Y_train)\n",
        "test=FashionDataset(X_test,Y_test)\n",
        "val=FashionDataset(X_val,Y_val)\n",
        "\n",
        "\n",
        "train_dl=DataLoader(train,batch_size = 50, shuffle=\"True\")\n",
        "test_dl=DataLoader(test,batch_size = 50, shuffle=\"True\")\n",
        "val_dl=DataLoader(val,batch_size = 50, shuffle=\"True\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUC50CVc_hom",
        "colab_type": "code",
        "outputId": "3e6e0d01-755c-42af-db23-c205307eef7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "for idx, data in enumerate(train_dl):\n",
        "  image,label=data\n",
        "  plt.imshow(image[0].cpu().data)\n",
        "  if(idx==5):\n",
        "    break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haxyKkTXobl2",
        "colab_type": "text"
      },
      "source": [
        "**Q1.c (2 pts):** Create a neural network model to classify the Fashion-MNIST dataset. Describe your model architecture in your writeup as well as explain your rationale in your writeup.\n",
        "\n",
        "**Note:** You may not use convolutional layers, **only** linear  layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFEMl-qtouL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(784,950)\n",
        "    self.fc2 = nn.Linear(950,350)\n",
        "    self.fc3  = nn.Linear(350,10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz1hkWiasU2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net=MLP()\n",
        "net.cuda()\n",
        "optim = optim.Adam(net.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLgAIDjsKPYO",
        "colab_type": "code",
        "outputId": "295c2f34-8470-4058-8135-d810c7ffbe89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=950, bias=True)\n",
              "  (fc2): Linear(in_features=950, out_features=350, bias=True)\n",
              "  (fc3): Linear(in_features=350, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "248Y7kbpuCdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "ACCURACY_DIR = \"Q8 Final A\" # Sub-Directory for storing this specific experiment's logs\n",
        "LOSS_DIR = \"Q8 Final L\"\n",
        "q2_acc_after = SummaryWriter(os.path.join(ROOT_LOG_DIR, ACCURACY_DIR))\n",
        "q2_loss_after = SummaryWriter(os.path.join(ROOT_LOG_DIR, LOSS_DIR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMwslhesD4Yh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir {ROOT_LOG_DIR.replace(\" \", \"\\\\ \")}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsHLTlq_lR3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir {ROOT_LOG_DIR.replace(\"\", \"/content/drive/My Drive/logs/Q8 Final L \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fK9HSfd1D8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/logs/Q8FinalA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ10XovKnLv4",
        "colab_type": "text"
      },
      "source": [
        "**Q1.d:** Create a training loop that takes in a dataloader of the training set, an optimizer, a loss function, and a model and trains that model. Your training loop should run for 5 epochs. Make sure to include Tensorboard integration so that you can graph your training curves.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sAIQUoan2jJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_dl, optim, loss_func, net):\n",
        "  #training loop\n",
        "  net.to(device)\n",
        "  graph = SummaryWriter()\n",
        "  overall_step = 0\n",
        "  for epoch in range(5): \n",
        "      overall_loss = 0.0\n",
        "      correct_values=0\n",
        "      overall_loss=0\n",
        "      instances=0\n",
        "      for idx,data in enumerate(train_dl):\n",
        "        image,label=data\n",
        "        image, label = image.to(device), label.to(device)   #sending to gpu\n",
        "        optim.zero_grad()\n",
        "        image=image.view(image.size(0),-1)       #flattening the images\n",
        "        Y_pred=net(image)\n",
        "        loss = loss_func(Y_pred,label)\n",
        "        overall_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        overall_step+=1\n",
        "        predicted_value=torch.argmax(Y_pred,1)\n",
        "        instances += image.size(0)\n",
        "        correct_values+=(predicted_value == label).sum().item()\n",
        "        # print(correct_values,instances)\n",
        "        # if idx % 200 == 0:\n",
        "        #   print((overall_loss)/(idx+1))\n",
        "      # print(correct_values)\n",
        "      accuracy = correct_values /len(train_dl.dataset)\n",
        "      avg_loss = overall_loss /idx+1\n",
        "      print(accuracy*100,avg_loss)\n",
        "      # print(avg_loss)\n",
        "      q2_acc_after.add_scalar(\"Q8 Final A\", accuracy*100, overall_step+1)\n",
        "      q2_loss_after.add_scalar(\"Q8 Final L\", avg_loss, overall_step+1) \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWDJnVJV6VqH",
        "colab_type": "code",
        "outputId": "2e26da73-551b-43f0-80bf-206cf61d95bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "result=train_model(train_dl, optim, loss_func, net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.03928571428571 1.4903832900939613\n",
            "86.47321428571428 1.3659320874863752\n",
            "87.86785714285715 1.3290186217179567\n",
            "88.68035714285715 1.3033074919230923\n",
            "89.38214285714285 1.283082610637056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sdEELmSn3On",
        "colab_type": "text"
      },
      "source": [
        "Create a test loop that takes in a test set dataloader and a trained model and calculates the final test accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcV_H8pxoXsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(test_dl, net,loss_func):\n",
        "  with torch.no_grad(): \n",
        "    overall_loss = 0.0\n",
        "    correct_values=0\n",
        "    overall_loss=0\n",
        "    instances=0\n",
        "    for idx,data in enumerate(test_dl):\n",
        "      image,label=data\n",
        "      image, label = image.to(device), label.to(device)\n",
        "      optim.zero_grad()\n",
        "      image=image.view(image.size(0),-1)\n",
        "      Y_pred=net(image)\n",
        "      loss = loss_func(Y_pred,label)\n",
        "      overall_loss += loss.item()\n",
        "      predicted_value=torch.argmax(Y_pred,1)\n",
        "      instances += image.size(0)\n",
        "      correct_values+=(predicted_value == label).sum().item()\n",
        "    accuracy = correct_values /len(test_dl.dataset)\n",
        "    avg_loss = overall_loss /idx+1\n",
        "    print(accuracy*100,avg_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IibLVeGM3yfp",
        "colab_type": "code",
        "outputId": "6a90beb1-7e5e-465e-8fa1-94a9da43bacb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result_test=test_model(test_dl,net,loss_func)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.54642857142858 1.2499147332868505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiTse7bcoy59",
        "colab_type": "text"
      },
      "source": [
        "**Q1.e (2 pts):** Finally, put this all together. Plot your training curve and record your final training / test accuracy, and put this in your writeup. You should get an accuracy of at least 80%. Tune hyperparameters using your validation set, and describe in your writeup how you tuned your hyperparameters / explain your final hyperparameter choices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIQnhDSupeKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=train_model(train_dl, optim, loss_func, net)\n",
        "result_test=test_model(test_dl,net,loss_func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTvitxrACaSp",
        "colab_type": "text"
      },
      "source": [
        "Now for submission purposes, complete the following header that returns a Numpy array with the predictions (i.e. a 0-9 label for which class each sample belongs to) for an input of the same form that you've been training with (fashion_input_data.dill)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnSfs7eXCcNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output: Return a numpy array with a 0-9 label for each sample in the input numpy array\n",
        "# (i.e. an np array whose contents are of the form: [0, 3, 2, 4, ... , 8])\n",
        "\n",
        "def generate_fashion_mnist_outputs(input):\n",
        "  p=[]\n",
        "  net.to(device)\n",
        "  for idx,data in enumerate(input):\n",
        "    data=data.reshape(-1,28*28)\n",
        "    actual=torch.FloatTensor(data)\n",
        "    actual=actual.to(device)\n",
        "    Y_pred=net(actual)\n",
        "    _,predicted_value=torch.max(Y_pred.data,1)\n",
        "    p.append(predicted_value.item())\n",
        "  p=np.array(p)\n",
        "  return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS_4We4xCRii",
        "colab_type": "code",
        "outputId": "c3a1dab3-7f48-4da3-e865-bca8d4344a31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_case_1e = generate_fashion_mnist_output(generate_fashion_mnist_outputs)\n",
        "test_case_1e"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 5, 6, ..., 3, 9, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM8HNC_UNBKQ",
        "colab_type": "text"
      },
      "source": [
        "# Q2 Neural Network Diagnoses, Part 2 (80 pts)\n",
        "\n",
        "We're now ready to get started diagnosing. Below are 10 different training experiments. Follow the instructions, and for each experiment, state the issue you identified in your writeup. When you finish fixing the experiment, plot the new learning curve and report your final accuracy.\n",
        "\n",
        "**Note: you should not need to run your training loop for more than 5 epochs.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_UJwNd6e_fy",
        "colab_type": "text"
      },
      "source": [
        "For each question below, we will provide 4 PyTorch objects: a DataLoader, a neural network model, an optimizer, and a loss function (you will load them using dill, a serialization library in Python).  For each question, please complete the following:\n",
        "\n",
        "a.   Train the given neural net using the given DataLoader, optimizer and loss function. You can reuse your training and testing loops from part 1. Plot the learning curve of the network using tensorboard and report the final training and testing accuracy in your writeup.\n",
        "\n",
        "b.   You should see that the neural net is not training correctly. Debug the issue (e.g. printing parameters, gradients, outputs) and report your methodology in your writeup.\n",
        "\n",
        "c.   When you identify an issue with any of the 4 given objects, replace the buggy object with one of your own making.  Then retrain the neural net, plot the new learning curve, and report the improved training / testing accuracy in your writeup.  **Note that in each of the following problems, exactly 1 object will be buggy.  You should not have to replace more than 1.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qjUyylkrYNL",
        "colab_type": "text"
      },
      "source": [
        "**Important**: Make sure to upload the .pkl files to Colab before beginning with the diagnoses. To upload, simply click the files icon in the top left corner of the screen, click upload and upload the \"dills\" folder that we provided you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6oCxoBPjG0q",
        "colab_type": "text"
      },
      "source": [
        "###Q2.0 Diagnosis 0 (8 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gPvceFWIpHG",
        "colab_type": "text"
      },
      "source": [
        "Let's jump into the process of diagnosing a neural network experiment first step by step.\n",
        "\n",
        "First, we start by loading the dataloaders, neural network, optimizer, and loss function from our pickle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFPCffe1KZW5",
        "colab_type": "code",
        "outputId": "dc5ae798-5c26-46a7-87ec-aa57b97e6074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q0.pkl\", 'rb') as f:\n",
        "  q0_creator = dill.load(f)\n",
        "train_dl_0, test_dl_0, net_0, loss_func_0, optim_0 = q0_creator()\n",
        "net=MLP()\n",
        "optim = optim.Adam(net.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#network\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=950, bias=True)\n",
              "  (fc2): Linear(in_features=950, out_features=350, bias=True)\n",
              "  (fc3): Linear(in_features=350, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_jlfsN-KgtJ",
        "colab_type": "text"
      },
      "source": [
        "**Q2.0a**. Next, write some code to train your model on the data, loss function, and optimizer provided. In your writeup, provide a screenshot of the learning curve from tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgGD2XPQr0pq",
        "colab_type": "code",
        "outputId": "ce6dc09f-09a9-437e-cf39-38a8110c0193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "a=train_model(train_dl_0,optim_0,loss_func_0,net_0.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10.040000000000001 3.307167007847501\n",
            "29.05333333333333 2.47440626127692\n",
            "40.525 2.3343096792399383\n",
            "48.928333333333335 2.2463785190017074\n",
            "54.50166666666667 2.1501579955344603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlD6qaH2Lmsb",
        "colab_type": "text"
      },
      "source": [
        "**Q2.0b**. Evaluate your learning curve. Does the given model perform as well as your benchmark? Write your findings in the writeup.\n",
        "\n",
        "**Q2.0c**. Try printing out some of the neural network components that were given to you. What do you notice out of the ordinary about any of them? Record this in your writeup.\n",
        "\n",
        "**Q2.0d**. Once you think you've pinpointed the reason this net is not training well, replace this component with a fixed version (so if the problem was the optimizer, replace the optimizer with a fixed one), and re-run the training and testing loop using the fixed component. Report the training curve in your writeup as well as the training / testing accuracy. Verify that your fixed experiment achieves greater than 80% test accuracy.\n",
        "\n",
        "**Q2.0e** Explain in the writeup what you discovered was the issue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIOt-G2DNgP0",
        "colab_type": "code",
        "outputId": "6a13efd3-927c-4a4c-fb50-62841f5b38aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "\n",
        "a=train_model(train_dl_0,optim,loss_func_0,net)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.19 1.4945784344995559\n",
            "86.81833333333333 1.358663583364033\n",
            "88.14333333333333 1.3195643192141602\n",
            "89.10333333333334 1.2934073661026453\n",
            "89.81166666666667 1.2718721106648445\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uvriuCVPWxq",
        "colab_type": "code",
        "outputId": "2d2fea6a-2657-4e84-8d65-af97f41c6a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl_0,net,loss_func_0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.66000000000001 1.3396578340819387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pInKH8sNfKoG",
        "colab_type": "text"
      },
      "source": [
        "### Q2.1 Diagnosis 1 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q1.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UTDn_Vk-3GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q1.pkl\", 'rb') as f:\n",
        "  q1_creator = dill.load(f)\n",
        "train_dl_1, test_dl_1, net_1, loss_func_1, optim_1 = q1_creator()\n",
        "net=MLP()\n",
        "optim = optim.SGD(net.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#training\n",
        "a=train_model(train_dl_1,optim_1,loss_func_1,net_1.cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-VKHoJnOgkP",
        "colab_type": "code",
        "outputId": "cc5663c0-a087-49e9-cc71-6d6775e21033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Run training and testing here for Question 2.1\n",
        "a=train_model(train_dl,optim_1,loss_func_1,net_1.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.93214285714285 0.47837212083349007\n",
            "86.73035714285714 0.36076602057693524\n",
            "88.10357142857143 0.32769088411938824\n",
            "88.82857142857142 0.3064309591592719\n",
            "89.425 0.28937599905437156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYlANO4SdEDB",
        "colab_type": "code",
        "outputId": "8a66e26e-7408-4299-b563-133071e286ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl,net_1.cuda(),loss_func_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.19464285714285 0.2769036277443395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OIZ_8zfqN0xM"
      },
      "source": [
        "### Q2.2 Diagnosis 2 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q2.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4lU2iw7fN0xT",
        "outputId": "e0ea1741-3c7c-462a-85a4-0895dbf3f8af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q2.pkl\", 'rb') as f:\n",
        "  q2_creator = dill.load(f)\n",
        "train_dl_2, test_dl_2, net_2, loss_func_2, optim_2 = q2_creator()\n",
        "net=MLP()\n",
        "optim = optim.Adam(net.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#network\n",
        "a=train_model(train_dl_2,optim_2,loss_func_2,net_2.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.913333333333334 3.306444371084936\n",
            "9.906666666666666 3.30644384927065\n",
            "9.916666666666666 3.3064438488726227\n",
            "9.841666666666667 3.306443838921931\n",
            "9.788333333333334 3.3064438639976745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDbi_OjhF0Ta",
        "colab_type": "code",
        "outputId": "93732755-8dde-4aa4-dd2b-864cea4a7f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "a=train_model(train_dl_2,optim_2,loss_func_2,net_2.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.02302600297133128\n",
            "0.0 0.023025997761885325\n",
            "0.0 0.02302599775791168\n",
            "0.0 0.023025997658570607\n",
            "0.0 0.023025997908910117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kjfz8eo2OmWh",
        "outputId": "e952201a-189a-4979-d608-feef66f17285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Run training and testing here for Question 2.2\n",
        "a=train_model(train_dl_2,optim,loss_func_2,net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.11666666666667 1.495374470750159\n",
            "86.76333333333334 1.3589445707545256\n",
            "88.14166666666667 1.3198428835614098\n",
            "89.03666666666666 1.294058780103474\n",
            "89.755 1.2716033554858277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6jfCbQfduUt",
        "colab_type": "code",
        "outputId": "38c5bc82-d656-41ba-c722-2df63a07f55a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl_2,net,loss_func_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.79 1.345340487932918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ojCCn5STN194"
      },
      "source": [
        "### Q2.3 Diagnosis 3 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q3.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bVUg9Cc9N199",
        "outputId": "8c3ed51a-2461-4cce-b49f-3229a936f0cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q3.pkl\", 'rb') as f:\n",
        "  q3_creator = dill.load(f)\n",
        "train_dl_3, test_dl_3, net_3, loss_func_3, optim_3 = q3_creator()\n",
        "net=MLP()\n",
        "optim = optim.SGD(net.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#loss function\n",
        "a=train_model(train_dl_3,optim_3,loss_func_3,net_3.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.585 11.01669449081803\n",
            "14.585 11.01669449081803\n",
            "14.585 11.01669449081803\n",
            "14.585 11.01669449081803\n",
            "14.585 11.01669449081803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lv6r6FPYOm-H",
        "outputId": "b30ac163-5d1a-41ec-c170-822f3ee4cf24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Run training and testing here for Question 2.3\n",
        "a=train_model(train_dl_3,optim_3,loss_func,net_3.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "76.70333333333333 1.7468328090362837\n",
            "83.89 1.4761365085392444\n",
            "85.395 1.4274140913816844\n",
            "86.24166666666667 1.3993986121849942\n",
            "86.80166666666666 1.3793426763036214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVo2sJTmh2bJ",
        "colab_type": "code",
        "outputId": "ce5d944c-ad9a-481e-d8a7-c6aae6573150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl_3,net_3.cuda(),loss_func)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85.66 1.4135329654120437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m3dKPhM_N2Z-"
      },
      "source": [
        "### Q2.4 Diagnosis 4 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q4.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tsYJjKFnN2aC",
        "outputId": "45468c27-9cac-4b9e-ad9c-deb84726a004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q4.pkl\", 'rb') as f:\n",
        "  q4_creator = dill.load(f)\n",
        "train_dl_4, test_dl_4, net_4, loss_func_4, optim_4 = q4_creator()\n",
        "net=MLP()\n",
        "optim = optim.Adam(net_4.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#optimiser\n",
        "a=train_model(train_dl_4,optim_4,loss_func_4,net_4.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.496666666666666 3.3152293000675006\n",
            "5.496666666666666 3.3152293000675006\n",
            "5.496666666666666 3.3152293000675006\n",
            "5.496666666666666 3.3152293000675006\n",
            "5.496666666666666 3.3152293000675006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Kn5Om3wOnsu",
        "outputId": "c55c90ab-9693-4087-9d59-35b99251bce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Run training and testing here for Question 2.4\n",
        "a=train_model(train_dl_4,optim,loss_func_4,net_4.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.23666666666666 1.5012864655813511\n",
            "86.745 1.3671551221151383\n",
            "88.155 1.325613342063853\n",
            "89.075 1.299194205807326\n",
            "89.85666666666667 1.2776902241380466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeY2BJoNmPU-",
        "colab_type": "code",
        "outputId": "7b86177f-fe7a-4120-d045-f9aa5f5b259f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl_4,net_4.cuda(),loss_func)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.52 1.3446383125553227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lE0rHO6rN21R"
      },
      "source": [
        "### Q2.5 Diagnosis 5 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q5.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eiHV5xveN21V",
        "outputId": "46ddefff-35a7-44cd-c3e1-ad15990aa025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q5.pkl\", 'rb') as f:\n",
        "  q5_creator = dill.load(f)\n",
        "train_dl_5, test_dl_5, net_5, loss_func_5, optim_5 = q5_creator()\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#train data\n",
        "a=train_model(train_dl_5,optim_5,loss_func_5,net_5.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78.08657786885246 1.9231125720036335\n",
            "86.20645491803278 1.4906295984983444\n",
            "89.47233606557377 1.3862901559242835\n",
            "90.72745901639344 1.3421513829857874\n",
            "91.45747950819673 1.3115499682533436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FJJQgCxkOoRr",
        "outputId": "d97d68af-41d6-47f7-a285-3f6349b08613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Run training and testing here for Question 2.5\n",
        "a=train_model(train_dl,optim_5,loss_func_5,net_5.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89.98035714285714 0.27770182816525446\n",
            "90.38214285714285 0.26557816870252854\n",
            "90.67142857142856 0.2552185069749955\n",
            "91.00357142857143 0.24727004971658711\n",
            "91.31071428571428 0.2396220112623913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8BU5DbceweF",
        "colab_type": "code",
        "outputId": "eed48376-6873-4976-9bb0-586b613455ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl,net_5.cuda(),loss_func_5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91.55357142857142 0.23825422346930386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qaP5BcfnN3UC"
      },
      "source": [
        "### Q2.6 Diagnosis 6 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q6.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gFbGG6i2N3UH",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q6.pkl\", 'rb') as f:\n",
        "  q6_creator = dill.load(f)\n",
        "train_dl_6, test_dl_6, net_6, loss_func_6, optim_6 = q6_creator()\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#training data\n",
        "a=train_model(train_dl_6,optim_6,loss_func_6,net_6.cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i362kGDpOpDO",
        "outputId": "a77ce237-29a7-495c-c958-d9f283299a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "a=train_model(train_dl,optim_6,loss_func_6,net_6.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.91071428571428 0.4792761838540817\n",
            "86.92857142857143 0.36044210576697205\n",
            "88.05714285714285 0.3279697089731011\n",
            "88.78571428571429 0.30469544287857053\n",
            "89.36964285714286 0.28989311887597574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-z6iY9UkN86",
        "colab_type": "code",
        "outputId": "1dae3651-74a8-41c5-9413-08f05a683324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl,net_6.cuda(),loss_func_6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.36785714285715 0.2630995687370553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fGb8qJt7N3pB"
      },
      "source": [
        "### Q2.7 Diagnosis 7 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q7.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NF4PaWcmN3pG",
        "outputId": "3b8f682e-cab3-4477-8b43-5983598ce2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q7.pkl\", 'rb') as f:\n",
        "  q7_creator = dill.load(f)\n",
        "train_dl_7, test_dl_7, net_7, loss_func_7, optim_7 = q7_creator()\n",
        "net=MLP()\n",
        "optim = optim.SGD(net.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#training data\n",
        "a=train_model(train_dl_7,optim_7,loss_func_7,net_7.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42.32 2.9361689825089825\n",
            "46.07833333333333 2.866684025038463\n",
            "46.82833333333333 2.8471216671852915\n",
            "47.265 2.834135127585002\n",
            "47.638333333333335 2.823936331451238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q6bL3xcWOpuz",
        "colab": {}
      },
      "source": [
        "# Run training and testing here for Question 2.7\n",
        "a=train_model(train_dl,optim_7,loss_func_7,net_7.cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvkojX_Qlsla",
        "colab_type": "code",
        "outputId": "7c0da4ed-67a3-4d19-b809-6dffd1f0b263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl,net_7.cuda(),loss_func_7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.64285714285715 0.254499868623065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NDvKohv6N3_K"
      },
      "source": [
        "### Q2.8 Diagnosis 8 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q8.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o2rnrvOvN3_S",
        "outputId": "07a703c7-01a9-490d-8c36-d633c6528f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q8.pkl\", 'rb') as f:\n",
        "  q8_creator = dill.load(f)\n",
        "train_dl_8, test_dl_8, net_8, loss_func_8, optim_8 = q8_creator()\n",
        "net=MLP()\n",
        "optim = optim.Adam(net_8.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#optimiser\n",
        "# a=train_model(train_dl_8,optim_8,loss_func_8,net_8.cuda())\n",
        "a=train_model(train_dl_8,optim,loss_func_8,net_8.cuda())"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82.29333333333332 1.5002594325249898\n",
            "86.795 1.3643804904763805\n",
            "88.16000000000001 1.3249613481242588\n",
            "89.08666666666667 1.2981894231947118\n",
            "89.77666666666667 1.27755865947233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aR3gNZY2Oqtu",
        "colab": {}
      },
      "source": [
        "# Run training and testing here for Question 2.8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UMwPvi4nsQ5",
        "colab_type": "code",
        "outputId": "5c36f61c-70a4-4bb2-9341-6d95337cbd31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl_8,net_8.cuda(),loss_func_8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.92999999999999 1.3385732524623775\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jAtpVuQlOEiE"
      },
      "source": [
        "### Q2.9 Diagnosis 9 (8 pts)\n",
        "\n",
        "Perform the same steps as Q2.0 a-e but for the ```dills/q9.pkl``` file instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lzPcchSVOEiJ",
        "outputId": "210ced88-3a36-4508-cbab-bc4f4ee3fc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/dills/q9.pkl\", 'rb') as f:\n",
        "  q9_creator = dill.load(f)\n",
        "train_dl_9, test_dl_9, net_9, loss_func_9, optim_9 = q9_creator()\n",
        "net=MLP()\n",
        "optim = optim.Adam(net.parameters(), lr=0.001)\n",
        "net.cuda()\n",
        "net.to(device)\n",
        "#network\n",
        "# a=train_model(train_dl_9,optim_9,loss_func_9,net_9.cuda())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (fc1): Linear(in_features=784, out_features=950, bias=True)\n",
              "  (fc2): Linear(in_features=950, out_features=350, bias=True)\n",
              "  (fc3): Linear(in_features=350, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mN4nWT28Orh3",
        "colab": {}
      },
      "source": [
        "# Run training and testing here for Question 2.9\n",
        "a=train_model(train_dl_9,optim,loss_func_9,net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z-pFV7NtkcS",
        "colab_type": "code",
        "outputId": "1ffc90b5-a70e-4698-a2a0-986e0764a287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=test_model(test_dl_9,net,loss_func_9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87.2 1.3568024638325278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-Br7dx1bm9Jw"
      },
      "source": [
        "# Q3: Applying what you've learned (10 pts)\n",
        "\n",
        "Now that you've had some experience debugging some neural network experiment, try and apply what you've learned to set up a working experiment for a new dataset.\n",
        "\n",
        "In this question, you'll be training a network on a harder dataset, [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html). \n",
        "\n",
        "**Q3.a**: Create testing, training and validation PyTorch dataloaders for this dataset, with appropriate parameters. As before, **do not** use the built in PyTorch dataloader for CIFAR-10 but instead the data that we provide you. From any of these dataloaders, visualize an image, and put that image in your writeup.\n",
        "\n",
        "**Data:** We've given you the data in the form of two pickled files:\n",
        "*   cifar_10_input_data.dill\n",
        "*   cifar_10_labels.dill\n",
        "\n",
        "The first pickled file contains the input data that you should be training with as a pickled 4-dimensional numpy array. The RGB images are 3x32x32, so each individual image is stored along the first axis (i.e. if you index into [7, 1, 3, 5] you're indexing into the \"Red\" channel\" pixel at row 3, column 5).\n",
        "\n",
        "The second pickled file is a numpy array that contains the labels for the input data stored as numbers from 0-9.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrJolGvVlTF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/data/cifar_10_data/cifar_10_input_data.dill\",'rb') as fid:\n",
        "  cifar_data  = dill.load(fid)\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/Release/data/cifar_10_data/cifar_10_labels.dill\",'rb') as fl:\n",
        "  cifar_label = dill.load(fl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gDUsxLQsjXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CifarDataset(Dataset):\n",
        "    def __init__(self,X,y):\n",
        "      self.X=cifar_data\n",
        "      self.y=cifar_label\n",
        "  \n",
        "    def __len__(self):\n",
        "     return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      image=self.X[idx].reshape(3,32,32)\n",
        "      label=self.y[idx]\n",
        "     \n",
        "      return image,label\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLj4dYtDs8Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(cifar_data,cifar_label, test_size=0.1, random_state=1)  # splitting total as test-10 and train-90\n",
        "X_train,X_val,Y_train, Y_val = train_test_split(X_train,Y_train,test_size=0.2222, random_state=1) # splitting train-90 as train-70 and val-20 (0.222*90/100 =20)\n",
        "\n",
        "train=CifarDataset(X_train,Y_train)\n",
        "test=CifarDataset(X_test,Y_test)\n",
        "val=CifarDataset(X_val,Y_val)\n",
        "\n",
        "\n",
        "train_dl=DataLoader(train,batch_size = 50,shuffle='True')\n",
        "test_dl=DataLoader(test,batch_size = 50,shuffle='True')\n",
        "val_dl=DataLoader(val,batch_size = 50,shuffle='True')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDSP_C0dtKcd",
        "colab_type": "code",
        "outputId": "3319bf5b-6ea9-49b7-fdf1-5f16549ce6a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "for idx, data in enumerate(train_dl):\n",
        "  image,label=data\n",
        "  plt.imshow(image[0][2].cpu().data)\n",
        "  if(idx==5):\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEXeRzhDlT3_",
        "colab_type": "text"
      },
      "source": [
        "**Q3.b**: Now, create your network model, testing and training loops to train your network. Plot the training curve using tensorboard, and add this plot to your writeup along with the final training and testing accuracy. Describe how you tuned your hyperparameters in your writeup along with your final hyperparameter choices. \n",
        "\n",
        "**Note: Do not use any convolutional layers.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEr9XZ8mlrTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "class MLP_Cifar(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP_Cifar, self).__init__()\n",
        "    self.fc1 = nn.Linear(3072,3900)\n",
        "    self.fc2 = nn.Linear(3900,1200)\n",
        "    self.fc3  = nn.Linear(1200,10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.leaky_relu(self.fc1(x))\n",
        "    x = F.leaky_relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMGdedynt_8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netw=MLP_Cifar()\n",
        "netw.cuda()\n",
        "optim = optim.Adam(netw.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr3w4sWEubtS",
        "colab_type": "code",
        "outputId": "edac0d7b-6d56-4ce4-f842-e6920f4e4ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "netw.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP_Cifar(\n",
              "  (fc1): Linear(in_features=3072, out_features=3900, bias=True)\n",
              "  (fc2): Linear(in_features=3900, out_features=1200, bias=True)\n",
              "  (fc3): Linear(in_features=1200, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c44HtBrxujE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "ACCURACY_DIR = \"Cifar correct accuracy\" # Sub-Directory for storing this specific experiment's logs\n",
        "LOSS_DIR = \"Cifar proper Loss\"\n",
        "cifar_acccorrect = SummaryWriter(os.path.join(ROOT_LOG_DIR, ACCURACY_DIR))\n",
        "cifar_lossproper = SummaryWriter(os.path.join(ROOT_LOG_DIR, LOSS_DIR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu1-hhZzuol9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir {ROOT_LOG_DIR.replace(\" \", \"\\\\ \")}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQuq3cFAuv55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_dl, optim, loss_func, netw):\n",
        "  #training loop\n",
        "  netw.to(device)\n",
        "  graph = SummaryWriter()\n",
        "  overall_step = 0\n",
        "  for epoch in range(10): \n",
        "      overall_loss = 0.0\n",
        "      correct_values=0\n",
        "      overall_loss=0\n",
        "      instances=0\n",
        "      for idx,data in enumerate(train_dl):\n",
        "        image,label=data\n",
        "        image, label = image.to(device), label.to(device)   #sending to gpu\n",
        "        optim.zero_grad()\n",
        "        image=image.view(image.size(0),-1)       #flattening the images\n",
        "        Y_pred=netw(image)\n",
        "        loss = loss_func(Y_pred,label)\n",
        "        overall_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        overall_step+=1\n",
        "        predicted_value=torch.argmax(Y_pred,1)\n",
        "        instances += image.size(0)\n",
        "        correct_values+=(predicted_value == label).sum().item()\n",
        "        # print(correct_values,instances)\n",
        "        # if idx % 200 == 0:\n",
        "        #   print((overall_loss)/(idx+1))\n",
        "      # print(correct_values)\n",
        "      accuracy = correct_values /len(train_dl.dataset)\n",
        "      avg_loss = overall_loss /idx+1\n",
        "      print(accuracy*100,avg_loss)\n",
        "      # print(avg_loss)\n",
        "      cifar_acccorrect.add_scalar('Cifar correct accuracy', accuracy*100, overall_step+1)\n",
        "      cifar_lossproper.add_scalar('Cifar proper loss', avg_loss, overall_step+1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDAzHWVwwAZr",
        "colab_type": "code",
        "outputId": "696d3e3a-f724-41e9-93af-d0d36daabb68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "result=train_model(train_dl, optim, loss_func, netw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33.29814814814815 2.842042209927521\n",
            "40.885185185185186 2.645367124988814\n",
            "43.8 2.5666452015407444\n",
            "45.62407407407407 2.5212991949139756\n",
            "47.053703703703704 2.4833008963493866\n",
            "47.72777777777778 2.458592212122828\n",
            "48.894444444444446 2.431386057429009\n",
            "49.67962962962963 2.4092081051606398\n",
            "50.43518518518518 2.3844530206791665\n",
            "51.16851851851851 2.36877452288655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BMmhNSywA7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(test_dl, netw,loss_func):\n",
        "  with torch.no_grad(): \n",
        "    overall_loss = 0.0\n",
        "    correct_values=0\n",
        "    overall_loss=0\n",
        "    instances=0\n",
        "    for idx,data in enumerate(test_dl):\n",
        "      image,label=data\n",
        "      image, label = image.to(device), label.to(device)\n",
        "      optim.zero_grad()\n",
        "      image=image.view(image.size(0),-1)\n",
        "      Y_pred=netw(image)\n",
        "      loss = loss_func(Y_pred,label)\n",
        "      overall_loss += loss.item()\n",
        "      predicted_value=torch.argmax(Y_pred,1)\n",
        "      instances += image.size(0)\n",
        "      correct_values+=(predicted_value == label).sum().item()\n",
        "    accuracy = correct_values /len(test_dl.dataset)\n",
        "    avg_loss = overall_loss /idx+1\n",
        "    print(accuracy*100,avg_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqPgA2xbwMCi",
        "colab_type": "code",
        "outputId": "6c950a2d-d24a-4311-f5a3-79d47cd4273c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result_test=test_model(test_dl,netw,loss_func)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53.11296296296296 2.304047352357304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRaeaioTlrzS",
        "colab_type": "text"
      },
      "source": [
        "Now for submission purposes, complete the following header that returns a Numpy array with the predictions (i.e. a 0-9 label for which class each sample belongs to) for an input 3 dimensional numpy array containing CIFAR-10 data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwPH4QUlViHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Output: Return a numpy array with a 0-9 label for each sample in the input numpy array\n",
        "# (i.e. an np array whose contents are of the form: [0, 3, 2, 4, ... , 8])\n",
        "\n",
        "def generate_cifar_10_outputs(input):\n",
        "  p=[]\n",
        "  netw.to(device)\n",
        "  for idx,data in enumerate(input):\n",
        "    data=data.reshape(-1,3*32*32)\n",
        "    actual=torch.FloatTensor(data)\n",
        "    actual=actual.to(device)\n",
        "    Y_pred=netw(actual)\n",
        "    _,predicted_value=torch.max(Y_pred.data,1)\n",
        "    p.append(predicted_value.item())\n",
        "  p=np.array(p)\n",
        "  return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xpve_C8Viaa",
        "colab_type": "code",
        "outputId": "523df032-ac31-4e58-ce8a-e9eb67084f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_case_3b = generate_cifar_output(generate_cifar_10_outputs)\n",
        "test_case_3b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 1, ..., 1, 2, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7HoEeQgmH9W",
        "colab_type": "text"
      },
      "source": [
        "## Submission Instructions\n",
        "\n",
        "The deadline for all parts of this assignment is **February 13, 2020 at 11:59pm**. \n",
        "\n",
        "There are two submissions on Gradescope:\n",
        "*   HW2 - Deep Learning Diagnostics (Writeup)\n",
        "*   HW2 - Deep Learning Diagnostics (Programming)\n",
        "\n",
        "For *HW2 - Deep Learning Diagnostics (Writeup)* submit your written responses to the questions above as the file **\"522_HW2_writeup.pdf\"**\n",
        "\n",
        "For *HW2 - Deep Learning Diagnostics (Programming)* submit the following files as your submission:\n",
        "1.   522_HW2_submission.dill\n",
        "2.   This notebook, named as 522_HW2_notebook.ipynb\n",
        "\n",
        "**Leaderboard:** When you submit, you can choose to add yourself as part of the leaderboard! Extra credit may be awarded to those that perform particularly well on the leaderboard.\n",
        "\n",
        "**Gradescope Score:** After you submit, you'll see that all of the classifier questions are out of zero points. To encourage as much hypertuning, we will not be releasing the accuracy cutoffs until after the late deadline has passed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1jE-Lcj8sbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dill\n",
        "import os\n",
        "\n",
        "file_to_obj_map = {\n",
        "    'test_case_1e' : test_case_1e,\n",
        "    'test_case_3b' : test_case_3b,\n",
        "}\n",
        "\n",
        "tests_path = \"522_HW2_submission.dill\"\n",
        "with open(tests_path, 'wb') as pickle_file:\n",
        "  dill.dump(file_to_obj_map, pickle_file)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}